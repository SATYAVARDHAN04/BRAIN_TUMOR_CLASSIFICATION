{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Science Project: Brain Tumor Detection (BTD) from MRI Scans**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Authors: Sofiene HERMI, Hajer JRAD, Riadh ZIDI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Phase 1: Business Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Medical Context**\n",
    "The detection and characterization of brain tumors is a major public health challenge. MRI (Magnetic Resonance Imaging) is the primary diagnostic tool for detecting and characterizing brain tumors. The three tumor types in our dataset have distinct characteristics:\n",
    "\n",
    "- **Glioma**: Primary brain tumor developing from glial cells; often aggressive and requires prompt treatment.\n",
    "- **Meningioma**: Usually benign tumor arising from the meninges; more common in women.\n",
    "- **Pituitary tumor**: Tumor of the pituitary gland, usually benign but can affect hormone levels.\n",
    "\n",
    "### **2. Project Objectives**\n",
    "**Main objective:**\n",
    "Develop an automatic classification system that performs:\n",
    "\n",
    "- **Binary detection:** Identify presence or absence of a tumor.\n",
    "- **Multi-class classification:** If a tumor is detected, determine its type among the three categories.\n",
    "\n",
    "**Secondary objectives:**\n",
    "\n",
    "- Assist radiologists in early diagnosis\n",
    "- Reduce MRI analysis time\n",
    "- Provide a second opinion for validation\n",
    "- Improve diagnostic accessibility in under-resourced areas\n",
    "\n",
    "**Success criteria:**\n",
    "\n",
    "- **Overall accuracy:** > 90% on the test set\n",
    "- **Sensitivity (Recall):** > 95% for tumor detection (minimize false negatives)\n",
    "- **Specificity:** > 90% to avoid false positives\n",
    "- Balanced confusion matrix across classes\n",
    "\n",
    "**Constraints & considerations:**\n",
    "\n",
    "- **Medical ethics:** The model is an aid, not a replacement for clinical diagnosis\n",
    "- **Interpretability:** Importance of understanding model decisions\n",
    "- **Class imbalance:** Handle the lower number of 'no_tumor' images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Phase 2: Data Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any transformation, an exploratory data analysis (EDA) is necessary to validate image quality.\n",
    "\n",
    "**Distribution analysis:** The numerical disparity between the \"Tumor\" and \"No_tumor\" classes may bias the model toward detection errors (e.g., higher false negatives).\n",
    "\n",
    "**Visual variance analysis:** Images in the \"no_tumor\" class show variable dimensions, whereas tumor images are often 512x512. A uniform resizing step is required to ensure consistent input tensors.\n",
    "\n",
    "**Integrity check:** Visual inspection using pixel histograms helps verify that brightness and contrast are consistent across folders, preventing the model from learning acquisition artifacts instead of pathology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T19:34:14.202674Z",
     "iopub.status.busy": "2026-01-20T19:34:14.20196Z",
     "iopub.status.idle": "2026-01-20T19:34:16.274727Z",
     "shell.execute_reply": "2026-01-20T19:34:16.273407Z",
     "shell.execute_reply.started": "2026-01-20T19:34:14.202638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T08:17:49.116187Z",
     "iopub.status.busy": "2026-01-18T08:17:49.115779Z",
     "iopub.status.idle": "2026-01-18T08:17:49.1205Z",
     "shell.execute_reply": "2026-01-18T08:17:49.119836Z",
     "shell.execute_reply.started": "2026-01-18T08:17:49.116145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Dataset path\n",
    "BASE_PATH = '/kaggle/input/brain-tumor-classification-mri'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 DATASET STRUCTURE EXPLORATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T08:17:53.752025Z",
     "iopub.status.busy": "2026-01-18T08:17:53.751461Z",
     "iopub.status.idle": "2026-01-18T08:17:56.833392Z",
     "shell.execute_reply": "2026-01-18T08:17:56.832718Z",
     "shell.execute_reply.started": "2026-01-18T08:17:53.751999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_info = {\n",
    "    'Training': defaultdict(int),\n",
    "    'Testing': defaultdict(int)\n",
    "}\n",
    "\n",
    "image_dimensions = {\n",
    "    'Training': defaultdict(list),\n",
    "    'Testing': defaultdict(list)\n",
    "}\n",
    "\n",
    "# Parcourir Training et Testing\n",
    "for split in ['Training', 'Testing']:\n",
    "    split_path = os.path.join(BASE_PATH, split)\n",
    "    \n",
    "    if not os.path.exists(split_path):\n",
    "        print(f\"\\n Le dossier {split} n'existe pas!\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n Dossier: {split}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Parcourir les classes\n",
    "    for class_name in os.listdir(split_path):\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        \n",
    "        if os.path.isdir(class_path):\n",
    "            # Compter les images\n",
    "            images = [f for f in os.listdir(class_path) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            count = len(images)\n",
    "            dataset_info[split][class_name] = count\n",
    "            \n",
    "            print(f\"  ├─ {class_name:25s}: {count:4d} images\")\n",
    "            \n",
    "            # Échantillonner quelques images pour analyser les dimensions\n",
    "            sample_size = min(50, count)\n",
    "            for img_name in images[:sample_size]:\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    image_dimensions[split][class_name].append(img.size)\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    total = sum(dataset_info[split].values())\n",
    "    print(f\"  └─ {'TOTAL':25s}: {total:4d} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 IMAGE DIMENSIONS ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T21:08:07.694557Z",
     "iopub.status.busy": "2026-01-17T21:08:07.694302Z",
     "iopub.status.idle": "2026-01-17T21:08:07.702137Z",
     "shell.execute_reply": "2026-01-17T21:08:07.701166Z",
     "shell.execute_reply.started": "2026-01-17T21:08:07.694533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for split in ['Training', 'Testing']:\n",
    "    print(f\"\\n {split}:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for class_name, dims in image_dimensions[split].items():\n",
    "        if dims:\n",
    "            widths = [d[0] for d in dims]\n",
    "            heights = [d[1] for d in dims]\n",
    "            \n",
    "            unique_dims = set(dims)\n",
    "            \n",
    "            print(f\"\\n  {class_name}:\")\n",
    "            print(f\"    Dimensions uniques: {len(unique_dims)}\")\n",
    "            \n",
    "            if len(unique_dims) == 1:\n",
    "                print(f\"    Taille uniforme: {dims[0][0]}x{dims[0][1]}\")\n",
    "            else:\n",
    "                print(f\"    Largeur  - Min: {min(widths):4d}, Max: {max(widths):4d}, Moyenne: {np.mean(widths):.1f}\")\n",
    "                print(f\"    Hauteur  - Min: {min(heights):4d}, Max: {max(heights):4d}, Moyenne: {np.mean(heights):.1f}\")\n",
    "                print(f\"    Dimensions les plus fréquentes: {max(set(dims), key=dims.count)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 CLASS IMBALANCE ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T21:10:27.069063Z",
     "iopub.status.busy": "2026-01-17T21:10:27.068794Z",
     "iopub.status.idle": "2026-01-17T21:10:27.099681Z",
     "shell.execute_reply": "2026-01-17T21:10:27.098874Z",
     "shell.execute_reply.started": "2026-01-17T21:10:27.069041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for split in ['Training', 'Testing']:\n",
    "    print(f\"\\n {split}:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    counts = dataset_info[split]\n",
    "    if not counts:\n",
    "        continue\n",
    "        \n",
    "    total = sum(counts.values())\n",
    "    \n",
    "    # Créer un DataFrame pour l'analyse\n",
    "    df = pd.DataFrame({\n",
    "        'Classe': list(counts.keys()),\n",
    "        'Nombre': list(counts.values()),\n",
    "        'Pourcentage': [v/total*100 for v in counts.values()]\n",
    "    })\n",
    "    \n",
    "    df = df.sort_values('Nombre', ascending=False)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Ratio de déséquilibre\n",
    "    max_count = max(counts.values())\n",
    "    min_count = min(counts.values())\n",
    "    imbalance_ratio = max_count / min_count if min_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\n  Ratio de déséquilibre: {imbalance_ratio:.2f}:1\")\n",
    "    print(f\"  (Classe majoritaire / Classe minoritaire)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4 VISUALISATION DES ÉCHANTILLONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T21:11:43.006199Z",
     "iopub.status.busy": "2026-01-17T21:11:43.005841Z",
     "iopub.status.idle": "2026-01-17T21:11:44.506388Z",
     "shell.execute_reply": "2026-01-17T21:11:44.505551Z",
     "shell.execute_reply.started": "2026-01-17T21:11:43.006168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "split = 'Training'\n",
    "split_path = os.path.join(BASE_PATH, split)\n",
    "classes = sorted([d for d in os.listdir(split_path) \n",
    "                 if os.path.isdir(os.path.join(split_path, d))])\n",
    "\n",
    "samples_per_class = 3\n",
    "\n",
    "fig, axes = plt.subplots(len(classes), samples_per_class, \n",
    "                         figsize=(15, 4*len(classes)))\n",
    "fig.suptitle('Échantillons d\\'images par classe (Training)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(split_path, class_name)\n",
    "    images = [f for f in os.listdir(class_path) \n",
    "             if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Sélectionner des échantillons aléatoires\n",
    "    samples = np.random.choice(images, \n",
    "                              min(samples_per_class, len(images)), \n",
    "                              replace=False)\n",
    "    \n",
    "    for j, img_name in enumerate(samples):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        ax = axes[i, j] if len(classes) > 1 else axes[j]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        if j == 0:\n",
    "            ax.set_title(f\"{class_name}\\n{img.shape}\", \n",
    "                       fontsize=10, fontweight='bold')\n",
    "        else:\n",
    "            ax.set_title(f\"{img.shape}\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5 PIXEL STATISTICAL ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T21:13:08.907431Z",
     "iopub.status.busy": "2026-01-17T21:13:08.907141Z",
     "iopub.status.idle": "2026-01-17T21:13:21.524338Z",
     "shell.execute_reply": "2026-01-17T21:13:21.523633Z",
     "shell.execute_reply.started": "2026-01-17T21:13:08.907411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "split = 'Training'\n",
    "split_path = os.path.join(BASE_PATH, split)\n",
    "classes = sorted([d for d in os.listdir(split_path) \n",
    "                 if os.path.isdir(os.path.join(split_path, d))])\n",
    "\n",
    "sample_size = 100\n",
    "stats = {}\n",
    "\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(split_path, class_name)\n",
    "    images = [f for f in os.listdir(class_path) \n",
    "             if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Échantillonner\n",
    "    samples = np.random.choice(images, \n",
    "                              min(sample_size, len(images)), \n",
    "                              replace=False)\n",
    "    \n",
    "    pixel_values = []\n",
    "    \n",
    "    for img_name in samples:\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        pixel_values.extend(img.flatten())\n",
    "    \n",
    "    pixel_values = np.array(pixel_values)\n",
    "    \n",
    "    stats[class_name] = {\n",
    "        'mean': np.mean(pixel_values),\n",
    "        'std': np.std(pixel_values),\n",
    "        'min': np.min(pixel_values),\n",
    "        'max': np.max(pixel_values),\n",
    "        'median': np.median(pixel_values)\n",
    "    }\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"\\n Statistiques (sur {sample_size} images par classe):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "df_stats = pd.DataFrame(stats).T\n",
    "df_stats = df_stats.round(2)\n",
    "print(df_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.6 PIXEL INTENSITY DISTRIBUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T21:14:23.699662Z",
     "iopub.status.busy": "2026-01-17T21:14:23.699388Z",
     "iopub.status.idle": "2026-01-17T21:15:37.685822Z",
     "shell.execute_reply": "2026-01-17T21:15:37.684778Z",
     "shell.execute_reply.started": "2026-01-17T21:14:23.699641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n Génération des histogrammes de distribution...\")\n",
    "\n",
    "split = 'Training'\n",
    "split_path = os.path.join(BASE_PATH, split)\n",
    "classes = sorted([d for d in os.listdir(split_path) \n",
    "                 if os.path.isdir(os.path.join(split_path, d))])\n",
    "\n",
    "sample_size_hist = 50\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Distribution des intensités de pixels par classe', \n",
    "             fontsize=16, fontweight='bold')\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(split_path, class_name)\n",
    "    images = [f for f in os.listdir(class_path) \n",
    "             if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    samples = np.random.choice(images, \n",
    "                              min(sample_size_hist, len(images)), \n",
    "                              replace=False)\n",
    "    \n",
    "    pixel_values = []\n",
    "    for img_name in samples:\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        pixel_values.extend(img.flatten())\n",
    "    \n",
    "    axes[idx].hist(pixel_values, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_title(f'{class_name} (n={len(samples)} images)')\n",
    "    axes[idx].set_xlabel('Intensité de pixel')\n",
    "    axes[idx].set_ylabel('Fréquence')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.7 GRAPHIQUES DE DISTRIBUTION DES CLASSES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T21:16:17.627633Z",
     "iopub.status.busy": "2026-01-17T21:16:17.627321Z",
     "iopub.status.idle": "2026-01-17T21:16:17.859096Z",
     "shell.execute_reply": "2026-01-17T21:16:17.85812Z",
     "shell.execute_reply.started": "2026-01-17T21:16:17.627612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n Génération des graphiques de distribution...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Distribution des classes dans le dataset', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, split in enumerate(['Training', 'Testing']):\n",
    "    counts = dataset_info[split]\n",
    "    if not counts:\n",
    "        continue\n",
    "    \n",
    "    classes_list = list(counts.keys())\n",
    "    values = list(counts.values())\n",
    "    \n",
    "    # Graphique en barres\n",
    "    bars = axes[idx].bar(classes_list, values, \n",
    "                        color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    axes[idx].set_title(f'{split} Set', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Nombre d\\'images', fontsize=12)\n",
    "    axes[idx].set_xlabel('Classes', fontsize=12)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                      f'{int(height)}',\n",
    "                      ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.8 EXPLORATORY PHASE SUMMARY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key findings:**\n",
    "- Dataset structured into Training/Testing\n",
    "- 4 classes: glioma_tumor, meningioma_tumor, pituitary_tumor, no_tumor\n",
    "- Significant imbalance: 'no_tumor' underrepresented\n",
    "- Variable dimensions in Testing; Training images are generally 512x512 except in the NO_TUMOR class\n",
    "\n",
    "### **Class distribution (Training)**\n",
    "\n",
    "Total: 2,870 images\n",
    "- Glioma: 826 (28.8%)\n",
    "- Meningioma: 822 (28.6%)\n",
    "- Pituitary: 827 (28.8%)\n",
    "- No Tumor: 395 (13.8%) -> Underrepresented\n",
    "\n",
    "### **Class distribution (Testing)**\n",
    "\n",
    "Total: 389 images\n",
    "Relatively balanced across classes\n",
    "\n",
    "### **Technical characteristics**\n",
    "- Training format: standardized 512×512 grayscale images\n",
    "- Testing format: JPG images of variable dimensions -> requires preprocessing\n",
    "- Channels: Grayscale images (1 channel)\n",
    "\n",
    "**Critical observation:** There is a significant class imbalance: pathological classes are overrepresented compared to the healthy class in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Phase 3: Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the pivotal step of our project. Here we aim to balance the Tumor and no_tumor classes. We will use K-means clustering to determine 200 representative clusters for each tumor type so that the total of the \"tumor\" class becomes 600 images (200+200+200). For augmenting the no_tumor class we will use a diffusion model to generate synthetic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T16:10:58.637857Z",
     "iopub.status.busy": "2026-01-19T16:10:58.637659Z",
     "iopub.status.idle": "2026-01-19T16:10:58.650695Z",
     "shell.execute_reply": "2026-01-19T16:10:58.650145Z",
     "shell.execute_reply.started": "2026-01-19T16:10:58.637832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T16:11:21.276894Z",
     "iopub.status.busy": "2026-01-19T16:11:21.276623Z",
     "iopub.status.idle": "2026-01-19T16:11:21.281873Z",
     "shell.execute_reply": "2026-01-19T16:11:21.281298Z",
     "shell.execute_reply.started": "2026-01-19T16:11:21.276872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/brain-tumor-classification-mri'\n",
    "OUTPUT_BASE = '/kaggle/working/kmeans_output'\n",
    "\n",
    "# Créer structure\n",
    "folders = [\n",
    "    'selected_images/glioma',\n",
    "    'selected_images/meningioma',\n",
    "    'selected_images/pituitary',\n",
    "    'original_no_tumor',\n",
    "    'metrics'\n",
    "]\n",
    "\n",
    "print(\"\\n Création structure...\")\n",
    "for folder in folders:\n",
    "    os.makedirs(os.path.join(OUTPUT_BASE, folder), exist_ok=True)\n",
    "print(f\" {len(folders)} dossiers créés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 STEP 1: K-MEANS TO SELECT 200 IMAGES PER TUMOR TYPE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Methodology:**\n",
    "\n",
    "### For each tumor type:\n",
    "\n",
    "1. Extract descriptors (features) from images (e.g., flattening, PCA, or CNN embeddings).\n",
    "2. Apply K-means with K = 200.\n",
    "3. Select one image per cluster (the image closest to the centroid).\n",
    "\n",
    "Thus, for each tumor type we obtain 200 representative images:\n",
    "\n",
    "- 200 Glioma\n",
    "- 200 Meningioma\n",
    "- 200 Pituitary\n",
    "\n",
    "These images are then merged to form a single 'tumor' class for the binary classification task.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- Selection guided by the data structure.\n",
    "- Reduced redundancy bias.\n",
    "- Better coverage of the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.1 IMAGE SELECTION WITH K-MEANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T16:11:33.976056Z",
     "iopub.status.busy": "2026-01-19T16:11:33.97575Z",
     "iopub.status.idle": "2026-01-19T16:16:06.25599Z",
     "shell.execute_reply": "2026-01-19T16:16:06.2553Z",
     "shell.execute_reply.started": "2026-01-19T16:11:33.976032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tumor_classes = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor']\n",
    "target_per_class = 200\n",
    "image_size = (128, 128)\n",
    "\n",
    "print(f\"\\nObjectif: {target_per_class} images par classe\")\n",
    "print(f\"Métriques: Inertie, Silhouette, Davies-Bouldin\")\n",
    "\n",
    "kmeans_metrics = {}\n",
    "\n",
    "for tumor_class in tumor_classes:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Traitement: {tumor_class}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    class_path = os.path.join(BASE_PATH, 'Training', tumor_class)\n",
    "    all_images = [f for f in os.listdir(class_path) \n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    print(f\"   Total: {len(all_images)}\")\n",
    "    \n",
    "    # Extraction features\n",
    "    features_list = []\n",
    "    valid_images = []\n",
    "    \n",
    "    for img_name in tqdm(all_images, desc=\"  Features\"):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(class_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "            img_resized = cv2.resize(img, image_size)\n",
    "            features = (img_resized.astype('float32') / 255.0).flatten()\n",
    "            features_list.append(features)\n",
    "            valid_images.append(img_name)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    features_array = np.array(features_list)\n",
    "    print(f\"   Features: {features_array.shape}\")\n",
    "    \n",
    "    # K-Means\n",
    "    print(f\"   K-Means (K={target_per_class})...\")\n",
    "    kmeans = KMeans(n_clusters=target_per_class, random_state=42, n_init=10, max_iter=300)\n",
    "    cluster_labels = kmeans.fit_predict(features_array)\n",
    "    \n",
    "    # Métriques\n",
    "    inertia = kmeans.inertia_\n",
    "    silhouette = silhouette_score(features_array, cluster_labels)\n",
    "    davies_bouldin = davies_bouldin_score(features_array, cluster_labels)\n",
    "    \n",
    "    print(f\"\\n   MÉTRIQUES:\")\n",
    "    print(f\"  • Inertie: {inertia:.2f}\")\n",
    "    print(f\"  • Silhouette: {silhouette:.4f}\")\n",
    "    print(f\"  • Davies-Bouldin: {davies_bouldin:.4f}\")\n",
    "    \n",
    "    kmeans_metrics[tumor_class] = {\n",
    "        'inertia': inertia,\n",
    "        'silhouette': silhouette,\n",
    "        'davies_bouldin': davies_bouldin\n",
    "    }\n",
    "    \n",
    "    # Sélection images\n",
    "    print(f\"\\n   Sélection images représentatives...\")\n",
    "    selected_indices = []\n",
    "    \n",
    "    for cluster_id in range(target_per_class):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_id)[0]\n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "        centroid = kmeans.cluster_centers_[cluster_id]\n",
    "        distances = np.linalg.norm(features_array[cluster_indices] - centroid, axis=1)\n",
    "        selected_indices.append(cluster_indices[np.argmin(distances)])\n",
    "    \n",
    "    selected_names = [valid_images[idx] for idx in selected_indices]\n",
    "    print(f\"   {len(selected_names)} images sélectionnées\")\n",
    "    \n",
    "    # Copier\n",
    "    class_short = tumor_class.replace('_tumor', '')\n",
    "    dest_path = os.path.join(OUTPUT_BASE, 'selected_images', class_short)\n",
    "    \n",
    "    for img_name in tqdm(selected_names, desc=\"  Copie\"):\n",
    "        shutil.copy2(os.path.join(class_path, img_name), \n",
    "                    os.path.join(dest_path, img_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.2 K-MEANS EVALUATION METRICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T16:16:17.652969Z",
     "iopub.status.busy": "2026-01-19T16:16:17.652665Z",
     "iopub.status.idle": "2026-01-19T16:16:17.657771Z",
     "shell.execute_reply": "2026-01-19T16:16:17.656963Z",
     "shell.execute_reply.started": "2026-01-19T16:16:17.652945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"{'Classe':<15} {'Inertie':<15} {'Silhouette':<15} {'Davies-Bouldin':<15}\")\n",
    "print(\"-\"*70)\n",
    "for tumor_class, metrics in kmeans_metrics.items():\n",
    "    class_name = tumor_class.replace('_tumor', '').upper()\n",
    "    print(f\"{class_name:<15} {metrics['inertia']:<15.2f} {metrics['silhouette']:<15.4f} {metrics['davies_bouldin']:<15.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T16:16:35.275389Z",
     "iopub.status.busy": "2026-01-19T16:16:35.275106Z",
     "iopub.status.idle": "2026-01-19T16:16:36.127033Z",
     "shell.execute_reply": "2026-01-19T16:16:36.126452Z",
     "shell.execute_reply.started": "2026-01-19T16:16:35.275365Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Métriques K-Means', fontsize=16, fontweight='bold')\n",
    "\n",
    "classes_short = [k.replace('_tumor', '') for k in kmeans_metrics.keys()]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "# Inertie\n",
    "inertia_vals = [kmeans_metrics[k]['inertia'] for k in kmeans_metrics.keys()]\n",
    "axes[0].bar(classes_short, inertia_vals, color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[0].set_title('Inertie (plus bas = meilleur)')\n",
    "axes[0].set_ylabel('Inertie')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(inertia_vals):\n",
    "    axes[0].text(i, v, f'{v:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Silhouette\n",
    "sil_vals = [kmeans_metrics[k]['silhouette'] for k in kmeans_metrics.keys()]\n",
    "axes[1].bar(classes_short, sil_vals, color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[1].axhline(y=0.5, color='green', linestyle='--', label='Excellent')\n",
    "axes[1].axhline(y=0.3, color='orange', linestyle='--', label='Bon')\n",
    "axes[1].set_title('Silhouette (plus haut = meilleur)')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(sil_vals):\n",
    "    axes[1].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Davies-Bouldin\n",
    "db_vals = [kmeans_metrics[k]['davies_bouldin'] for k in kmeans_metrics.keys()]\n",
    "axes[2].bar(classes_short, db_vals, color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[2].axhline(y=1.0, color='green', linestyle='--', label='Excellent')\n",
    "axes[2].axhline(y=1.5, color='orange', linestyle='--', label='Bon')\n",
    "axes[2].set_title('Davies-Bouldin (plus bas = meilleur)')\n",
    "axes[2].set_ylabel('Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(db_vals):\n",
    "    axes[2].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_BASE, 'metrics', 'kmeans_metrics.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.3 COPY ORIGINAL NO_TUMOR IMAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T16:16:50.141933Z",
     "iopub.status.busy": "2026-01-19T16:16:50.141636Z",
     "iopub.status.idle": "2026-01-19T16:16:52.603561Z",
     "shell.execute_reply": "2026-01-19T16:16:52.602815Z",
     "shell.execute_reply.started": "2026-01-19T16:16:50.141893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "no_tumor_path = os.path.join(BASE_PATH, 'Training', 'no_tumor')\n",
    "no_tumor_images = [f for f in os.listdir(no_tumor_path) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "print(f\"Total no_tumor: {len(no_tumor_images)}\")\n",
    "\n",
    "dest_no_tumor = os.path.join(OUTPUT_BASE, 'original_no_tumor')\n",
    "\n",
    "for img_name in tqdm(no_tumor_images, desc=\"Copie\"):\n",
    "    shutil.copy2(os.path.join(no_tumor_path, img_name), \n",
    "                os.path.join(dest_no_tumor, img_name))\n",
    "\n",
    "print(f\" {len(no_tumor_images)} images copiées\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T16:17:00.557752Z",
     "iopub.status.busy": "2026-01-19T16:17:00.557191Z",
     "iopub.status.idle": "2026-01-19T16:17:01.532573Z",
     "shell.execute_reply": "2026-01-19T16:17:01.531965Z",
     "shell.execute_reply.started": "2026-01-19T16:17:00.557725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CRÉER ZIP POUR TÉLÉCHARGEMENT\n",
    "# ==========================================\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_filename = f'kmeans_results_{timestamp}.zip'\n",
    "zip_path = os.path.join('/kaggle/working', zip_filename)\n",
    "\n",
    "print(f\"\\n Compression en cours...\")\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, dirs, files in os.walk(OUTPUT_BASE):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, OUTPUT_BASE)\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "zip_size = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "print(f\"  ZIP créé!\")\n",
    "print(f\"   Nom: {zip_filename}\")\n",
    "print(f\"   Taille: {zip_size:.2f} MB\")\n",
    "print(f\"   Emplacement: /kaggle/working/{zip_filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INSTRUCTIONS TÉLÉCHARGEMENT\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. Cliquez sur 'Output' dans le panneau droit\")\n",
    "print(f\"2. Trouvez: {zip_filename}\")\n",
    "print(\"3. Cliquez sur '...' puis 'Download'\")\n",
    "print(\"4. CONSERVEZ CE ZIP EN LOCAL!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n  PARTIE 1 TERMINÉE - TÉLÉCHARGEZ LE ZIP MAINTENANT!\")\n",
    "print(\"   Ensuite, exécutez la PARTIE 2 (Diffusion Model)\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 STEP 2: SYNTHETIC IMAGE GENERATION (DIFFUSION MODEL)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The tumor class initially contains about 400 images, which is insufficient for robust training of a deep model. Artificial augmentation is therefore necessary.\n",
    "\n",
    "### Classical methods (rotation, flip, noise) are limited and produce little semantic diversity. Diffusion models (**DDPM – Denoising Diffusion Probabilistic Models**) offer a powerful alternative.\n",
    "\n",
    "### **Principle of diffusion models:**\n",
    "\n",
    "### DDPMs rely on:\n",
    "\n",
    "### - A progressive noising process applied to images.\n",
    "\n",
    "### - A learned reverse process, implemented by a neural network, to reconstruct images.\n",
    "\n",
    "### - Once trained, the model can generate new realistic images that are statistically close to the original MRI images.\n",
    "\n",
    "### Why choose DDPMs:\n",
    "\n",
    "### - Ability to generate realistic medical images.\n",
    "\n",
    "### - Preservation of anatomical structures.\n",
    "\n",
    "### - Reduced overfitting through dataset diversification.\n",
    "\n",
    "### In this work, DDPMs are used to generate 200 synthetic images, bringing the tumor class to 600 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.1 GENERAL CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T08:21:25.704502Z",
     "iopub.status.busy": "2026-01-20T08:21:25.703816Z",
     "iopub.status.idle": "2026-01-20T08:21:25.708596Z",
     "shell.execute_reply": "2026-01-20T08:21:25.708059Z",
     "shell.execute_reply.started": "2026-01-20T08:21:25.704467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T08:21:30.904817Z",
     "iopub.status.busy": "2026-01-20T08:21:30.904248Z",
     "iopub.status.idle": "2026-01-20T08:21:30.9155Z",
     "shell.execute_reply": "2026-01-20T08:21:30.913648Z",
     "shell.execute_reply.started": "2026-01-20T08:21:30.904771Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/brain-tumor-classification-mri'\n",
    "OUTPUT_BASE = '/kaggle/working/ddpm_output'\n",
    "\n",
    "print(f\"Dataset original: {BASE_PATH}\")\n",
    "print(f\"Output: {OUTPUT_BASE}\")\n",
    "\n",
    "# Créer structure\n",
    "folders = [\n",
    "    'original_no_tumor',\n",
    "    'generated_images',\n",
    "    'model',\n",
    "    'samples'\n",
    "]\n",
    "\n",
    "print(\"\\n Création structure...\")\n",
    "for folder in folders:\n",
    "    os.makedirs(os.path.join(OUTPUT_BASE, folder), exist_ok=True)\n",
    "print(f\" {len(folders)} dossiers créés\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T08:21:34.894971Z",
     "iopub.status.busy": "2026-01-20T08:21:34.894348Z",
     "iopub.status.idle": "2026-01-20T08:21:35.628685Z",
     "shell.execute_reply": "2026-01-20T08:21:35.627904Z",
     "shell.execute_reply.started": "2026-01-20T08:21:34.894941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# COPIER NO_TUMOR ORIGINALES\n",
    "# ==========================================\n",
    "\n",
    "no_tumor_path = os.path.join(BASE_PATH, 'Training', 'no_tumor')\n",
    "no_tumor_images = [f for f in os.listdir(no_tumor_path) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "print(f\"Total no_tumor: {len(no_tumor_images)}\")\n",
    "\n",
    "temp_no_tumor = os.path.join(OUTPUT_BASE, 'original_no_tumor')\n",
    "\n",
    "for img_name in tqdm(no_tumor_images, desc=\"Copie\"):\n",
    "    shutil.copy2(os.path.join(no_tumor_path, img_name), \n",
    "                os.path.join(temp_no_tumor, img_name))\n",
    "\n",
    "print(f\" {len(no_tumor_images)} images copiées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T08:21:40.888856Z",
     "iopub.status.busy": "2026-01-20T08:21:40.888283Z",
     "iopub.status.idle": "2026-01-20T08:21:43.994436Z",
     "shell.execute_reply": "2026-01-20T08:21:43.993672Z",
     "shell.execute_reply.started": "2026-01-20T08:21:40.888826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# INSTALLATION DÉPENDANCES\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\" Installation diffusers, torch...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n",
    "                          \"diffusers\", \"transformers\", \"accelerate\", \"torch\", \"torchvision\"])\n",
    "    print(\" Dépendances installées!\")\n",
    "except Exception as e:\n",
    "    print(f\" Erreur: {e}\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from diffusers import DDPMScheduler, UNet2DModel, DDPMPipeline\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from tqdm.auto import tqdm as tqdm_auto\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n Device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.2 PRÉPARATION DU DATASET NO_TUMOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T08:21:56.457754Z",
     "iopub.status.busy": "2026-01-20T08:21:56.457168Z",
     "iopub.status.idle": "2026-01-20T08:21:56.465736Z",
     "shell.execute_reply": "2026-01-20T08:21:56.465038Z",
     "shell.execute_reply.started": "2026-01-20T08:21:56.457706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, image_dir, image_size=128):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = PILImage.open(img_path)\n",
    "        return self.transform(image)\n",
    "\n",
    "image_size = 128\n",
    "dataset = BrainMRIDataset(temp_no_tumor, image_size=image_size)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"  Dataset: {len(dataset)} images\")\n",
    "print(f\"   Batches: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.4 DDPM MODEL CONFIGURATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T08:22:05.686657Z",
     "iopub.status.busy": "2026-01-20T08:22:05.686066Z",
     "iopub.status.idle": "2026-01-20T08:22:06.7001Z",
     "shell.execute_reply": "2026-01-20T08:22:06.699227Z",
     "shell.execute_reply.started": "2026-01-20T08:22:05.686628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = UNet2DModel(\n",
    "    sample_size=image_size,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \n",
    "        \"DownBlock2D\", \"AttnDownBlock2D\", \"DownBlock2D\"\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \n",
    "        \"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"\n",
    "    ),\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "print(f\"   Modèle créé\")\n",
    "print(f\"   Paramètres: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.5 MODEL TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T08:22:12.495542Z",
     "iopub.status.busy": "2026-01-20T08:22:12.495056Z",
     "iopub.status.idle": "2026-01-20T10:12:12.744876Z",
     "shell.execute_reply": "2026-01-20T10:12:12.743929Z",
     "shell.execute_reply.started": "2026-01-20T08:22:12.495515Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "learning_rate = 1e-4\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  • Epochs: {num_epochs}\")\n",
    "print(f\"  • Learning rate: {learning_rate}\")\n",
    "print(f\"  • Batch size: 16\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=(len(dataloader) * num_epochs),\n",
    ")\n",
    "\n",
    "print(f\"\\n Démarrage...\")\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm_auto(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        clean_images = batch.to(device)\n",
    "        noise = torch.randn(clean_images.shape).to(device)\n",
    "        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, \n",
    "                                 (clean_images.shape[0],), device=device).long()\n",
    "        \n",
    "        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "        noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "        loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Échantillons tous les 10 epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pipeline = DDPMPipeline(unet=model, scheduler=noise_scheduler)\n",
    "            pipeline.to(device)\n",
    "            \n",
    "            samples = pipeline(batch_size=4, num_inference_steps=50, output_type=\"numpy\").images\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "            fig.suptitle(f'Epoch {epoch+1}', fontsize=14, fontweight='bold')\n",
    "            for i, ax in enumerate(axes):\n",
    "                img = (samples[i] * 255).astype(np.uint8)\n",
    "                ax.imshow(img[:, :, 0], cmap='gray')\n",
    "                ax.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUTPUT_BASE, 'samples', f'epoch_{epoch+1:03d}.png'))\n",
    "            plt.show()\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "print(\"\\n Entraînement terminé.\")\n",
    "\n",
    "# Courbe loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(losses, linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('DDPM Training Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(OUTPUT_BASE, 'training_loss.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.6 FINAL IMAGE GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T10:26:14.127095Z",
     "iopub.status.busy": "2026-01-20T10:26:14.126711Z",
     "iopub.status.idle": "2026-01-20T10:29:00.60496Z",
     "shell.execute_reply": "2026-01-20T10:29:00.604081Z",
     "shell.execute_reply.started": "2026-01-20T10:26:14.127047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "target_total = 600\n",
    "images_to_generate = target_total - len(no_tumor_images)\n",
    "\n",
    "print(f\"Images à générer: {images_to_generate}\")\n",
    "\n",
    "model.eval()\n",
    "pipeline = DDPMPipeline(unet=model, scheduler=noise_scheduler)\n",
    "pipeline.to(device)\n",
    "\n",
    "generated_folder = os.path.join(OUTPUT_BASE, 'generated_images')\n",
    "generated_count = 0\n",
    "batch_size_gen = 4\n",
    "\n",
    "print(\"\\n Génération en cours...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    while generated_count < images_to_generate:\n",
    "        try:\n",
    "            current_batch = min(batch_size_gen, images_to_generate - generated_count)\n",
    "            \n",
    "            output = pipeline(batch_size=current_batch, num_inference_steps=50, output_type=\"numpy\")\n",
    "            images = output.images\n",
    "            \n",
    "            for i in range(current_batch):\n",
    "                try:\n",
    "                    img = (images[i] * 255).astype(np.uint8)\n",
    "                    img_gray = img[:, :, 0]\n",
    "                    img_resized = cv2.resize(img_gray, (512, 512))\n",
    "                    \n",
    "                    save_path = os.path.join(generated_folder, f'ddpm_{generated_count:04d}.jpg')\n",
    "                    cv2.imwrite(save_path, img_resized)\n",
    "                    \n",
    "                    generated_count += 1\n",
    "                    \n",
    "                    if generated_count % 10 == 0:\n",
    "                        print(f\"  {generated_count}/{images_to_generate}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"   Erreur image {generated_count}: {e}\")\n",
    "                    generated_count += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   Erreur batch: {e}\")\n",
    "            if generated_count >= images_to_generate * 0.8:\n",
    "                break\n",
    "\n",
    "print(f\"\\n {generated_count} images générées\")\n",
    "\n",
    "# Vérification\n",
    "saved_imgs = [f for f in os.listdir(generated_folder) if f.lower().endswith('.jpg')]\n",
    "print(f\" Vérification: {len(saved_imgs)} fichiers\")\n",
    "\n",
    "# Comparaison visuelle\n",
    "print(\"\\n Comparaison...\")\n",
    "\n",
    "original_samples = no_tumor_images[:6]\n",
    "generated_samples = saved_imgs[:6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "fig.suptitle('Originales (haut) vs DDPM (bas)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, img_name in enumerate(original_samples):\n",
    "    img = cv2.imread(os.path.join(temp_no_tumor, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "    axes[0, idx].imshow(img, cmap='gray')\n",
    "    axes[0, idx].set_title('Original', fontsize=10, fontweight='bold')\n",
    "    axes[0, idx].axis('off')\n",
    "\n",
    "for idx, img_name in enumerate(generated_samples):\n",
    "    img = cv2.imread(os.path.join(generated_folder, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "    axes[1, idx].imshow(img, cmap='gray')\n",
    "    axes[1, idx].set_title('DDPM', fontsize=10, fontweight='bold')\n",
    "    axes[1, idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_BASE, 'comparison.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.3.7 SUMMARY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T10:29:26.524287Z",
     "iopub.status.busy": "2026-01-20T10:29:26.523563Z",
     "iopub.status.idle": "2026-01-20T10:29:26.528405Z",
     "shell.execute_reply": "2026-01-20T10:29:26.527683Z",
     "shell.execute_reply.started": "2026-01-20T10:29:26.52426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# RÉSUMÉ\n",
    "print(f\"  • Images originales: {len(no_tumor_images)}\")\n",
    "print(f\"  • Images générées: {generated_count}\")\n",
    "print(f\"  • Total: {len(no_tumor_images) + generated_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.4 Data Splitting**\n",
    "\n",
    "### 15% of the data from each class is reserved for validation.\n",
    "\n",
    "### The original Testing folder is kept for an independent final evaluation.\n",
    "\n",
    "### This choice follows best practices in machine learning and avoids information leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.4 FINAL VISUALIZATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T19:38:37.431443Z",
     "iopub.status.busy": "2026-01-20T19:38:37.430046Z",
     "iopub.status.idle": "2026-01-20T19:38:38.364085Z",
     "shell.execute_reply": "2026-01-20T19:38:38.362875Z",
     "shell.execute_reply.started": "2026-01-20T19:38:37.431396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATASET = '/kaggle/input/brain-tumor-balanced'\n",
    "# Compter\n",
    "distribution = {'binary': {}, 'multiclass': {}}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for class_name in ['tumor', 'no_tumor']:\n",
    "        path = os.path.join(DATASET, 'binary_classification', split, class_name)\n",
    "        count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        if split not in distribution['binary']:\n",
    "            distribution['binary'][split] = {}\n",
    "        distribution['binary'][split][class_name] = count\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for class_name in ['glioma', 'meningioma', 'pituitary']:\n",
    "        path = os.path.join(DATASET, 'multiclass_classification', split, class_name)\n",
    "        count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        if split not in distribution['multiclass']:\n",
    "            distribution['multiclass'][split] = {}\n",
    "        distribution['multiclass'][split][class_name] = count\n",
    "\n",
    "# Graphiques\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Distribution - Classification Binaire', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, split in enumerate(['train', 'validation', 'test']):\n",
    "    data = distribution['binary'][split]\n",
    "    axes[idx].bar(data.keys(), data.values(), color=['#FF6B6B', '#4ECDC4'], alpha=0.8, edgecolor='black')\n",
    "    axes[idx].set_title(f'{split.upper()}', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Images')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, (k, v) in enumerate(data.items()):\n",
    "        axes[idx].text(i, v, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Multi-classe\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Distribution - Classification Multi-classe', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, split in enumerate(['train', 'validation', 'test']):\n",
    "    data = distribution['multiclass'][split]\n",
    "    axes[idx].bar(data.keys(), data.values(), color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8, edgecolor='black')\n",
    "    axes[idx].set_title(f'{split.upper()}', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Images')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    axes[idx].tick_params(axis='x', rotation=15)\n",
    "    \n",
    "    for i, (k, v) in enumerate(data.items()):\n",
    "        axes[idx].text(i, v, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n CLASSIFICATION BINAIRE:\")\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for class_name in ['tumor', 'no_tumor']:\n",
    "        count = distribution['binary'][split][class_name]\n",
    "        print(f\"  {split:12s} / {class_name:10s}: {count:4d} images\")\n",
    "\n",
    "print(\"\\n CLASSIFICATION MULTI-CLASSE:\")\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for class_name in ['glioma', 'meningioma', 'pituitary']:\n",
    "        count = distribution['multiclass'][split][class_name]\n",
    "        print(f\"  {split:12s} / {class_name:11s}: {count:4d} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Phase 4 : Data Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Objectifs de la phase de modélisation:**\n",
    "\n",
    "### La phase de modélisation vise à concevoir, entraîner et comparer plusieurs modèles de Deep Learning afin d’identifier l’architecture la plus performante pour la tâche de classification des images IRM cérébrales. Conformément à la méthodologie CRISP-DM, cette phase s’appuie directement sur les décisions prises lors de la préparation des données.\n",
    "\n",
    "### Deux objectifs de modélisation sont poursuivis :\n",
    "\n",
    "### - Classification binaire : distinguer les patients atteints d’une tumeur cérébrale (tumor) de ceux sans tumeur (no_tumor).\n",
    "\n",
    "### - Classification multi-classes conditionnelle : identifier le type de tumeur (Glioma, Meningioma ou Pituitary) uniquement lorsque la présence d’une tumeur est détectée.\n",
    "\n",
    "### Dans cette section, l’accent est mis sur l’étude comparative de modèles de Transfer Learning, particulièrement adaptés aux jeux de données médicaux de taille limitée.\n",
    "\n",
    "### **Transfer Learning et imagerie médicale**\n",
    "\n",
    "### L’entraînement d’un réseau de neurones convolutifs profond à partir de zéro nécessite un volume de données massif, ce qui est rarement disponible en imagerie médicale. Le Transfer Learning consiste à exploiter des modèles pré-entraînés sur de larges bases de données (telles qu’ImageNet) afin de transférer les connaissances apprises vers une nouvelle tâche.\n",
    "\n",
    "### En imagerie médicale, cette approche présente plusieurs avantages :\n",
    "\n",
    "### - Réduction du temps d’entraînement.\n",
    "\n",
    "### - Meilleure convergence des modèles.\n",
    "\n",
    "### - Amélioration des performances malgré un nombre limité d’images annotées.\n",
    "\n",
    "### De nombreuses études ont montré que les premières couches d’un CNN apprennent des caractéristiques génériques (bords, textures), utiles également pour les images IRM.\n",
    "\n",
    "### **Modèles retenus:**\n",
    "\n",
    "### Deux architectures de référence ont été sélectionnées : EfficientNetB0 et DenseNet121. Ce choix repose sur leur efficacité démontrée dans des travaux récents en imagerie médicale.\n",
    "\n",
    "### **1. EfficientNetB0**\n",
    "\n",
    "### EfficientNet repose sur un principe de scaling composé, qui équilibre simultanément :\n",
    "\n",
    "### - la profondeur du réseau,\n",
    "\n",
    "### - la largeur des couches,\n",
    "\n",
    "### - la résolution des images.\n",
    "\n",
    "### EfficientNetB0 est la version de base de cette famille, offrant un excellent compromis entre : performance, nombre de paramètres, coût computationnel.\n",
    "\n",
    "### Ces caractéristiques en font un modèle particulièrement adapté aux environnements à ressources limitées et aux bases de données médicales.\n",
    "\n",
    "### **2 DenseNet121**\n",
    "\n",
    "### DenseNet121 appartient à la famille des réseaux densément connectés. Chaque couche reçoit en entrée les cartes de caractéristiques de toutes les couches précédentes.\n",
    "\n",
    "### Les principaux avantages de DenseNet121 sont :\n",
    "\n",
    "### - une meilleure propagation du gradient,\n",
    "\n",
    "### - une réutilisation efficace des caractéristiques,\n",
    "\n",
    "### - une réduction du risque de surapprentissage.\n",
    "\n",
    "### Ces propriétés sont particulièrement intéressantes pour la détection de structures fines et complexes, typiques des images IRM.\n",
    "\n",
    "### **Stratégies d’entraînement**\n",
    "\n",
    "### Pour chaque architecture, trois stratégies de Transfer Learning ont été mises en œuvre afin d’évaluer leur impact sur les performances.\n",
    "\n",
    "### **Mode 1 : Feature Extraction**\n",
    "\n",
    "### Dans ce mode :\n",
    "\n",
    "### Les poids du modèle pré-entraîné sont entièrement gelés.\n",
    "\n",
    "### Seules les couches finales (classifieur) sont entraînées.\n",
    "\n",
    "### Avantages : Entraînement rapide, risque limité de surapprentissage.\n",
    "\n",
    "### Limites : Adaptation restreinte aux spécificités des images IRM.\n",
    "\n",
    "### Ce mode constitue une base de référence pour la comparaison.\n",
    "\n",
    "### **Mode 2 : Fine-tuning total**\n",
    "\n",
    "### Dans ce mode :\n",
    "\n",
    "### L’ensemble des couches du modèle est entraîné.\n",
    "\n",
    "### Les poids pré-entraînés servent uniquement d’initialisation.\n",
    "\n",
    "### Avantages : Adaptation complète aux données IRM, Potentiel de performance maximal.\n",
    "\n",
    "### Limites : Risque accru de surapprentissage, coût computationnel plus élevé.\n",
    "\n",
    "### Cette stratégie est pertinente lorsque les données sont suffisamment diversifiées, notamment grâce à l’augmentation par modèles de diffusion.\n",
    "\n",
    "### **Mode 3 : Fine-tuning partiel**\n",
    "\n",
    "### Le fine-tuning partiel constitue un compromis entre les deux approches précédentes :\n",
    "\n",
    "### - Les premières couches (bas niveau) sont gelées.\n",
    "\n",
    "### - Les couches profondes sont réentraînées.\n",
    "\n",
    "### Avantages : Conservation des caractéristiques génériques, adaptation ciblée aux motifs spécifiques des tumeurs et Meilleur équilibre biais/variance.\n",
    "\n",
    "### This approach is often considered most suitable in medical imaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1. Library Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:25:12.34688Z",
     "iopub.status.busy": "2026-01-23T19:25:12.346651Z",
     "iopub.status.idle": "2026-01-23T19:25:30.202869Z",
     "shell.execute_reply": "2026-01-23T19:25:30.2023Z",
     "shell.execute_reply.started": "2026-01-23T19:25:12.346858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Importation des bibliothèques\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2. Configuration and Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:26:43.164957Z",
     "iopub.status.busy": "2026-01-23T19:26:43.164682Z",
     "iopub.status.idle": "2026-01-23T19:26:43.311028Z",
     "shell.execute_reply": "2026-01-23T19:26:43.310483Z",
     "shell.execute_reply.started": "2026-01-23T19:26:43.16493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Paramètres\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "BASE_PATH = '/kaggle/input/brain-tumor-balanced'\n",
    "\n",
    "# Prétraitement : EfficientNet gère le scaling en interne, \n",
    "# mais on applique de l'augmentation de données pour limiter le surapprentissage.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "test_val_datagen = ImageDataGenerator() # Pas d'augmentation pour val/test\n",
    "\n",
    "# 1. Générateurs BINAIRES\n",
    "train_gen_bin = train_datagen.flow_from_directory(\n",
    "    os.path.join(BASE_PATH, 'binary_classification/train'), \n",
    "    target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "val_gen_bin = test_val_datagen.flow_from_directory(\n",
    "    os.path.join(BASE_PATH, 'binary_classification/validation'),\n",
    "    target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=False)\n",
    "\n",
    "# 2. Générateurs MULTI-CLASSE\n",
    "train_gen_multi = train_datagen.flow_from_directory(\n",
    "    os.path.join(BASE_PATH, 'multiclass_classification/train'),\n",
    "    target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "\n",
    "val_gen_multi = test_val_datagen.flow_from_directory(\n",
    "    os.path.join(BASE_PATH, 'multiclass_classification/validation'),\n",
    "    target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3. Building the EfficientNetB0 Transfer Learning Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:26:53.277882Z",
     "iopub.status.busy": "2026-01-23T19:26:53.277152Z",
     "iopub.status.idle": "2026-01-23T19:26:53.282531Z",
     "shell.execute_reply": "2026-01-23T19:26:53.281718Z",
     "shell.execute_reply.started": "2026-01-23T19:26:53.277851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_efficientnet_model(num_classes, activation):\n",
    "    # Charger la base EfficientNetB0 pré-entraînée sur ImageNet\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False  # On gèle les poids au début\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Dense(num_classes, activation=activation)\n",
    "               \n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3.1 Binary Classification Model (Feature Extraction):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:26:59.753426Z",
     "iopub.status.busy": "2026-01-23T19:26:59.752739Z",
     "iopub.status.idle": "2026-01-23T19:27:05.97616Z",
     "shell.execute_reply": "2026-01-23T19:27:05.975427Z",
     "shell.execute_reply.started": "2026-01-23T19:26:59.753399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modèle 1 : Binaire (Tumor vs No Tumor)\n",
    "model_bin = build_efficientnet_model(1, 'sigmoid')\n",
    "model_bin.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:27:18.758712Z",
     "iopub.status.busy": "2026-01-23T19:27:18.758028Z",
     "iopub.status.idle": "2026-01-23T19:30:18.87363Z",
     "shell.execute_reply": "2026-01-23T19:30:18.873023Z",
     "shell.execute_reply.started": "2026-01-23T19:27:18.758684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history_bin = model_bin.fit(\n",
    "    train_gen_bin,\n",
    "    validation_data=val_gen_bin,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:31:53.119274Z",
     "iopub.status.busy": "2026-01-23T19:31:53.118626Z",
     "iopub.status.idle": "2026-01-23T19:31:53.125877Z",
     "shell.execute_reply": "2026-01-23T19:31:53.125169Z",
     "shell.execute_reply.started": "2026-01-23T19:31:53.119246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history, title=\"Évolution de l'entraînement\"):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Graphique de la Précision (Accuracy)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Précision Entraînement', color='#2ecc71', marker='o')\n",
    "    plt.plot(epochs_range, val_acc, label='Précision Validation', color='#e74c3c', marker='s')\n",
    "    plt.title(f'{title} - Précision')\n",
    "    plt.xlabel('Époques')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Graphique de la Perte (Loss)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Perte Entraînement', color='#2ecc71', marker='o')\n",
    "    plt.plot(epochs_range, val_loss, label='Perte Validation', color='#e74c3c', marker='s')\n",
    "    plt.title(f'{title} - Perte')\n",
    "    plt.xlabel('Époques')\n",
    "    plt.ylabel('Valeur de Perte')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:32:13.248502Z",
     "iopub.status.busy": "2026-01-23T19:32:13.248217Z",
     "iopub.status.idle": "2026-01-23T19:32:13.566697Z",
     "shell.execute_reply": "2026-01-23T19:32:13.566083Z",
     "shell.execute_reply.started": "2026-01-23T19:32:13.248479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  courbes de perte (Loss) et d'Accuracy\n",
    "plot_training_history(history_bin, title=\"Évolution de l'entraînement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:32:02.369122Z",
     "iopub.status.busy": "2026-01-23T19:32:02.36858Z",
     "iopub.status.idle": "2026-01-23T19:32:02.374438Z",
     "shell.execute_reply": "2026-01-23T19:32:02.373733Z",
     "shell.execute_reply.started": "2026-01-23T19:32:02.369087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation et matrice de confusion\n",
    "\n",
    "def evaluate_and_plot(model, generator, labels, title):\n",
    "    # Prédictions\n",
    "    preds = model.predict(generator)\n",
    "    if len(labels) == 2: # Cas binaire\n",
    "        y_pred = (preds > 0.5).astype(int).flatten()\n",
    "    else: # Cas multi-classe\n",
    "        y_pred = np.argmax(preds, axis=1)\n",
    "    \n",
    "    y_true = generator.classes\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'Matrice de Confusion : {title}')\n",
    "    plt.ylabel('Réalité')\n",
    "    plt.xlabel('Prédiction')\n",
    "    plt.show()\n",
    "\n",
    "    # Rapport de classification (Precision, Recall, F1)\n",
    "    print(f\"--- Rapport de classification : {title} ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:32:26.450159Z",
     "iopub.status.busy": "2026-01-23T19:32:26.449828Z",
     "iopub.status.idle": "2026-01-23T19:32:39.267227Z",
     "shell.execute_reply": "2026-01-23T19:32:39.266602Z",
     "shell.execute_reply.started": "2026-01-23T19:32:26.450098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Affichage pour le binaire\n",
    "evaluate_and_plot(model_bin, val_gen_bin, ['No Tumor', 'Tumor'], \"Classification Binaire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:35:29.978957Z",
     "iopub.status.busy": "2026-01-23T19:35:29.97821Z",
     "iopub.status.idle": "2026-01-23T19:35:31.124809Z",
     "shell.execute_reply": "2026-01-23T19:35:31.123998Z",
     "shell.execute_reply.started": "2026-01-23T19:35:29.97893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_bin.save('model_bin.h5') # Sauvegarde du modèle binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3.2 Multi-class Classification Model (Feature Extraction):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:42:57.580582Z",
     "iopub.status.busy": "2026-01-23T19:42:57.579849Z",
     "iopub.status.idle": "2026-01-23T19:42:58.859444Z",
     "shell.execute_reply": "2026-01-23T19:42:58.858877Z",
     "shell.execute_reply.started": "2026-01-23T19:42:57.580553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modèle 2 : Multi-classe (Glioma, Meningioma, Pituitary)\n",
    "model_multi = build_efficientnet_model(3, 'softmax')\n",
    "model_multi.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:43:12.189149Z",
     "iopub.status.busy": "2026-01-23T19:43:12.18883Z",
     "iopub.status.idle": "2026-01-23T19:48:16.246894Z",
     "shell.execute_reply": "2026-01-23T19:48:16.246358Z",
     "shell.execute_reply.started": "2026-01-23T19:43:12.189125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Entrainement du modèle multi-classe\n",
    "history_multi = model_multi.fit(\n",
    "    train_gen_multi,\n",
    "    validation_data=val_gen_multi,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:48:59.652631Z",
     "iopub.status.busy": "2026-01-23T19:48:59.651823Z",
     "iopub.status.idle": "2026-01-23T19:48:59.94303Z",
     "shell.execute_reply": "2026-01-23T19:48:59.942401Z",
     "shell.execute_reply.started": "2026-01-23T19:48:59.652605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  courbes de perte (Loss) et d'Accuracy\n",
    "plot_training_history(history_bin, title=\"Évolution de l'entraînement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:49:10.47525Z",
     "iopub.status.busy": "2026-01-23T19:49:10.474666Z",
     "iopub.status.idle": "2026-01-23T19:49:24.229707Z",
     "shell.execute_reply": "2026-01-23T19:49:24.229159Z",
     "shell.execute_reply.started": "2026-01-23T19:49:10.475216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation du modèle de classification multi-classe\n",
    "evaluate_and_plot(model_multi, val_gen_multi, ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor'], \"Classification Multiclasse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3.3. Fine-tuning total pour le modèle multi-classe :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:52:23.37012Z",
     "iopub.status.busy": "2026-01-23T19:52:23.369436Z",
     "iopub.status.idle": "2026-01-23T19:52:23.374436Z",
     "shell.execute_reply": "2026-01-23T19:52:23.373784Z",
     "shell.execute_reply.started": "2026-01-23T19:52:23.370075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# On dégèle le modèle de base\n",
    "def build_efficientnet_model(num_classes, activation):\n",
    "    # Charger la base EfficientNetB0 pré-entraînée sur ImageNet\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = True  # On gèle les poids au début\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Dense(num_classes, activation=activation)\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:52:36.415937Z",
     "iopub.status.busy": "2026-01-23T19:52:36.415317Z",
     "iopub.status.idle": "2026-01-23T19:52:37.353191Z",
     "shell.execute_reply": "2026-01-23T19:52:37.352395Z",
     "shell.execute_reply.started": "2026-01-23T19:52:36.415912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modèle 3 : Multi-classe (Glioma, Meningioma, Pituitary) avec Fine Tuning\n",
    "model_multi_fine = build_efficientnet_model(3, 'softmax')\n",
    "model_multi_fine.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5), \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:52:46.341673Z",
     "iopub.status.busy": "2026-01-23T19:52:46.340837Z",
     "iopub.status.idle": "2026-01-23T19:52:46.34554Z",
     "shell.execute_reply": "2026-01-23T19:52:46.344849Z",
     "shell.execute_reply.started": "2026-01-23T19:52:46.341642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # Arrête l'entraînement si la perte de validation ne baisse plus pendant 3 époques\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n",
    "    # Réduit le LR si le modèle stagne\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:52:59.260549Z",
     "iopub.status.busy": "2026-01-23T19:52:59.260268Z",
     "iopub.status.idle": "2026-01-23T19:59:05.225764Z",
     "shell.execute_reply": "2026-01-23T19:59:05.225167Z",
     "shell.execute_reply.started": "2026-01-23T19:52:59.260525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lancement du Fine-tuning\n",
    "history_fine = model_multi_fine.fit(\n",
    "    train_gen_multi,\n",
    "    validation_data=val_gen_multi,\n",
    "    epochs=10, \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:59:29.913508Z",
     "iopub.status.busy": "2026-01-23T19:59:29.913215Z",
     "iopub.status.idle": "2026-01-23T19:59:30.205904Z",
     "shell.execute_reply": "2026-01-23T19:59:30.205311Z",
     "shell.execute_reply.started": "2026-01-23T19:59:29.913483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_training_history(history_fine, title=\"Évolution de l'entraînement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T19:59:37.955358Z",
     "iopub.status.busy": "2026-01-23T19:59:37.954841Z",
     "iopub.status.idle": "2026-01-23T19:59:52.046013Z",
     "shell.execute_reply": "2026-01-23T19:59:52.045377Z",
     "shell.execute_reply.started": "2026-01-23T19:59:37.955332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation et matrice de confusion\n",
    "# Affichage pour le multiclasse\n",
    "evaluate_and_plot(model_multi_fine, val_gen_multi, ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor'], \"Classification Multiclasse avec Fine tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3.4. Fine-tuning partiel pour le modèle multi-classe :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:29:00.731797Z",
     "iopub.status.busy": "2026-01-23T21:29:00.731529Z",
     "iopub.status.idle": "2026-01-23T21:29:00.737471Z",
     "shell.execute_reply": "2026-01-23T21:29:00.736583Z",
     "shell.execute_reply.started": "2026-01-23T21:29:00.731778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# On dégèle le modèle de base\n",
    "def build_efficientnet_model(num_classes, activation):\n",
    "    # Charger la base EfficientNetB0 pré-entraînée sur ImageNet\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # nous avons choisi d’entraîner 78 couches, \n",
    "    # c’est-à-dire que nous allons geler\n",
    "    # les 160 premières couches et dégeler les autres :\n",
    "    for layer in base_model.layers[:160]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[160:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Dense(num_classes, activation=activation)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:29:05.563016Z",
     "iopub.status.busy": "2026-01-23T21:29:05.562284Z",
     "iopub.status.idle": "2026-01-23T21:29:06.593947Z",
     "shell.execute_reply": "2026-01-23T21:29:06.593375Z",
     "shell.execute_reply.started": "2026-01-23T21:29:05.562989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modèle 3 : Multi-classe (Glioma, Meningioma, Pituitary) avec Fine Tuning\n",
    "model_multi_fine = build_efficientnet_model(3, 'softmax')\n",
    "model_multi_fine.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5), \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:29:25.964864Z",
     "iopub.status.busy": "2026-01-23T21:29:25.964588Z",
     "iopub.status.idle": "2026-01-23T21:29:25.969221Z",
     "shell.execute_reply": "2026-01-23T21:29:25.96825Z",
     "shell.execute_reply.started": "2026-01-23T21:29:25.964841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # Arrête l'entraînement si la perte de validation ne baisse plus pendant 3 époques\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n",
    "    # Réduit le LR si le modèle stagne\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:29:30.102036Z",
     "iopub.status.busy": "2026-01-23T21:29:30.101782Z",
     "iopub.status.idle": "2026-01-23T21:34:43.185708Z",
     "shell.execute_reply": "2026-01-23T21:34:43.185116Z",
     "shell.execute_reply.started": "2026-01-23T21:29:30.102016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lancement du Fine-tuning\n",
    "history_fine = model_multi_fine.fit(\n",
    "    train_gen_multi,\n",
    "    validation_data=val_gen_multi,\n",
    "    epochs=10, \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:41:24.289145Z",
     "iopub.status.busy": "2026-01-23T21:41:24.288379Z",
     "iopub.status.idle": "2026-01-23T21:41:24.583946Z",
     "shell.execute_reply": "2026-01-23T21:41:24.58337Z",
     "shell.execute_reply.started": "2026-01-23T21:41:24.28909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_training_history(history_fine, title=\"Évolution de l'entraînement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:41:30.9093Z",
     "iopub.status.busy": "2026-01-23T21:41:30.908422Z",
     "iopub.status.idle": "2026-01-23T21:41:44.261889Z",
     "shell.execute_reply": "2026-01-23T21:41:44.261164Z",
     "shell.execute_reply.started": "2026-01-23T21:41:30.909272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation et matrice de confusion\n",
    "# Affichage pour le multiclasse\n",
    "evaluate_and_plot(model_multi_fine, val_gen_multi, ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor'], \"Classification Multiclasse avec Fine tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:45:03.95461Z",
     "iopub.status.busy": "2026-01-23T21:45:03.953839Z",
     "iopub.status.idle": "2026-01-23T21:45:05.171047Z",
     "shell.execute_reply": "2026-01-23T21:45:05.170458Z",
     "shell.execute_reply.started": "2026-01-23T21:45:03.954582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_multi_fine.save('model_multi_fine_partiel.h5') # Sauvegarde du modèle multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:53:35.850161Z",
     "iopub.status.busy": "2026-01-23T21:53:35.849573Z",
     "iopub.status.idle": "2026-01-23T21:53:35.855146Z",
     "shell.execute_reply": "2026-01-23T21:53:35.854437Z",
     "shell.execute_reply.started": "2026-01-23T21:53:35.850134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pipeline de décision finale\n",
    "\n",
    "def diagnostic_pipeline(image_path, model_bin, model_multi_fine):\n",
    "    # 1. Charger et préparer l'image\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # 2. Étape 1 : Détection de tumeur (Binaire)\n",
    "    is_tumor_prob = model_bin.predict(img_array)[0][0]\n",
    "    \n",
    "    if is_tumor_prob < 0.5:\n",
    "        return \"Résultat : Absence de tumeur détectée.\"\n",
    "    else:\n",
    "        # 3. Étape 2 : Si tumeur, classifier le type (Multi-classe)\n",
    "        type_preds = model_multi.predict(img_array)\n",
    "        classes_multi = ['Glioma', 'Meningioma', 'Pituitary']\n",
    "        detected_type = classes_multi[np.argmax(type_preds)]\n",
    "        return f\"Résultat : Tumeur détectée. Type suspecté : {detected_type} (Confiance : {np.max(type_preds)*100:.2f}%)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T23:25:05.867742Z",
     "iopub.status.busy": "2026-01-23T23:25:05.867449Z",
     "iopub.status.idle": "2026-01-23T23:25:21.475389Z",
     "shell.execute_reply": "2026-01-23T23:25:21.474681Z",
     "shell.execute_reply.started": "2026-01-23T23:25:05.867719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "test_img_path = '/kaggle/input/brain-tumor-balanced/multiclass_classification/test/pituitary/image(10).jpg'\n",
    "binary_model = load_model('/kaggle/input/model-for-deployement/other/default/1/model_bin_eff.h5')\n",
    "multi_model = load_model('/kaggle/input/model-for-deployement/other/default/1/model_multi_fine_partiel.h5')\n",
    "diagnostic_pipeline(test_img_path, binary_model, multi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4. Construction du modèle transfer learning DenseNet121**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:56:34.839275Z",
     "iopub.status.busy": "2026-01-23T21:56:34.838633Z",
     "iopub.status.idle": "2026-01-23T21:56:34.843887Z",
     "shell.execute_reply": "2026-01-23T21:56:34.843083Z",
     "shell.execute_reply.started": "2026-01-23T21:56:34.839248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "def build_densenet_model(num_classes, activation):\n",
    "    # Charger DenseNet121 pré-entraîné\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False # Geler pour le transfert initial\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Dense(num_classes, activation=activation)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4.1. Modèle binaire avec DenseNet121 :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:56:44.660148Z",
     "iopub.status.busy": "2026-01-23T21:56:44.6595Z",
     "iopub.status.idle": "2026-01-23T21:56:49.490632Z",
     "shell.execute_reply": "2026-01-23T21:56:49.490025Z",
     "shell.execute_reply.started": "2026-01-23T21:56:44.660091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Création du modèle binaire\n",
    "model_bin_dense = build_densenet_model(1, 'sigmoid')\n",
    "model_bin_dense.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T21:57:06.58088Z",
     "iopub.status.busy": "2026-01-23T21:57:06.580593Z",
     "iopub.status.idle": "2026-01-23T22:00:09.81555Z",
     "shell.execute_reply": "2026-01-23T22:00:09.814789Z",
     "shell.execute_reply.started": "2026-01-23T21:57:06.580856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history_bin_dense = model_bin_dense.fit(\n",
    "    train_gen_bin,\n",
    "    validation_data=val_gen_bin,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T21:41:06.512134Z",
     "iopub.status.busy": "2026-01-22T21:41:06.511306Z",
     "iopub.status.idle": "2026-01-22T21:41:07.072109Z",
     "shell.execute_reply": "2026-01-22T21:41:07.071509Z",
     "shell.execute_reply.started": "2026-01-22T21:41:06.512105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_bin_dense.save('model_bin_dense.h5') # Sauvegarde du modèle binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:00:29.844458Z",
     "iopub.status.busy": "2026-01-23T22:00:29.843873Z",
     "iopub.status.idle": "2026-01-23T22:00:30.133599Z",
     "shell.execute_reply": "2026-01-23T22:00:30.132958Z",
     "shell.execute_reply.started": "2026-01-23T22:00:29.84443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  courbes de perte (Loss) et d'Accuracy\n",
    "plot_training_history(history_bin_dense, title=\"Évolution de l'entraînement Binaire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:00:40.104188Z",
     "iopub.status.busy": "2026-01-23T22:00:40.103583Z",
     "iopub.status.idle": "2026-01-23T22:01:04.903705Z",
     "shell.execute_reply": "2026-01-23T22:01:04.903132Z",
     "shell.execute_reply.started": "2026-01-23T22:00:40.104156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Affichage pour le binaire\n",
    "evaluate_and_plot(model_bin_dense, val_gen_bin, ['No Tumor', 'Tumor'], \"Classification Binaire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4.2. Modèle multi-classe avec DenseNet121 (feature extraction):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:02:06.064875Z",
     "iopub.status.busy": "2026-01-23T22:02:06.064304Z",
     "iopub.status.idle": "2026-01-23T22:02:07.703608Z",
     "shell.execute_reply": "2026-01-23T22:02:07.702986Z",
     "shell.execute_reply.started": "2026-01-23T22:02:06.06485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Création du modèle multi-classe\n",
    "model_multi_dense = build_densenet_model(3, 'softmax')\n",
    "model_multi_dense.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:02:26.685971Z",
     "iopub.status.busy": "2026-01-23T22:02:26.685288Z",
     "iopub.status.idle": "2026-01-23T22:07:31.80606Z",
     "shell.execute_reply": "2026-01-23T22:07:31.805495Z",
     "shell.execute_reply.started": "2026-01-23T22:02:26.685938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Entrainement du modèle multi-classe\n",
    "history_multi_dense = model_multi_dense.fit(\n",
    "    train_gen_multi,\n",
    "    validation_data=val_gen_multi,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:08:11.691251Z",
     "iopub.status.busy": "2026-01-23T22:08:11.69067Z",
     "iopub.status.idle": "2026-01-23T22:08:11.972686Z",
     "shell.execute_reply": "2026-01-23T22:08:11.972086Z",
     "shell.execute_reply.started": "2026-01-23T22:08:11.691225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  courbes de perte (Loss) et d'Accuracy\n",
    "plot_training_history(history_multi_dense, title=\"Évolution de l'entraînement Multiclasse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:08:17.518086Z",
     "iopub.status.busy": "2026-01-23T22:08:17.517373Z",
     "iopub.status.idle": "2026-01-23T22:08:40.83041Z",
     "shell.execute_reply": "2026-01-23T22:08:40.829842Z",
     "shell.execute_reply.started": "2026-01-23T22:08:17.518059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation et matrice de confusion\n",
    "# Affichage pour le multiclasse\n",
    "evaluate_and_plot(model_multi_dense, val_gen_multi, ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor'], \"Classification Multiclasse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4.3. Fine-tuning total du Modèle multi-classe avec DenseNet121 :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:10:05.034387Z",
     "iopub.status.busy": "2026-01-23T22:10:05.034067Z",
     "iopub.status.idle": "2026-01-23T22:10:05.03932Z",
     "shell.execute_reply": "2026-01-23T22:10:05.038609Z",
     "shell.execute_reply.started": "2026-01-23T22:10:05.034363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "def build_densenet_model_fine(num_classes, activation):\n",
    "    # Charger DenseNet121 pré-entraîné\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = True # \n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Dense(num_classes, activation=activation)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:10:15.494246Z",
     "iopub.status.busy": "2026-01-23T22:10:15.493907Z",
     "iopub.status.idle": "2026-01-23T22:10:17.143738Z",
     "shell.execute_reply": "2026-01-23T22:10:17.143164Z",
     "shell.execute_reply.started": "2026-01-23T22:10:15.494219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modèle 3 : Multi-classe (Glioma, Meningioma, Pituitary) avec Fine Tuning\n",
    "model_multi_dense_fine = build_densenet_model_fine(3, 'softmax')\n",
    "model_multi_dense_fine.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5), \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:10:21.554814Z",
     "iopub.status.busy": "2026-01-23T22:10:21.554526Z",
     "iopub.status.idle": "2026-01-23T22:10:21.560097Z",
     "shell.execute_reply": "2026-01-23T22:10:21.559455Z",
     "shell.execute_reply.started": "2026-01-23T22:10:21.55479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # Arrête l'entraînement si la perte de validation ne baisse plus pendant 3 époques\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n",
    "    # Réduit le LR si le modèle stagne\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:10:55.847469Z",
     "iopub.status.busy": "2026-01-23T22:10:55.846869Z",
     "iopub.status.idle": "2026-01-23T22:19:46.332336Z",
     "shell.execute_reply": "2026-01-23T22:19:46.331549Z",
     "shell.execute_reply.started": "2026-01-23T22:10:55.847443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lancement du Fine-tuning\n",
    "history_dense_fine = model_multi_dense_fine.fit(\n",
    "    train_gen_multi,\n",
    "    validation_data=val_gen_multi,\n",
    "    epochs=10, \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:19:55.217891Z",
     "iopub.status.busy": "2026-01-23T22:19:55.216985Z",
     "iopub.status.idle": "2026-01-23T22:19:55.505945Z",
     "shell.execute_reply": "2026-01-23T22:19:55.50517Z",
     "shell.execute_reply.started": "2026-01-23T22:19:55.217863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  courbes de perte (Loss) et d'Accuracy\n",
    "plot_training_history(history_dense_fine, title=\"Évolution de l'entraînement Multiclasse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:20:04.584781Z",
     "iopub.status.busy": "2026-01-23T22:20:04.584492Z",
     "iopub.status.idle": "2026-01-23T22:20:28.452876Z",
     "shell.execute_reply": "2026-01-23T22:20:28.4522Z",
     "shell.execute_reply.started": "2026-01-23T22:20:04.584756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation et matrice de confusion\n",
    "# Affichage pour le multiclasse\n",
    "evaluate_and_plot(model_multi_dense_fine, val_gen_multi, ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor'], \"Classification Multiclasse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.4.4. Fine-tuning partiel du Modèle multi-classe avec DenseNet121 :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:25:56.981914Z",
     "iopub.status.busy": "2026-01-23T22:25:56.9816Z",
     "iopub.status.idle": "2026-01-23T22:25:58.588197Z",
     "shell.execute_reply": "2026-01-23T22:25:58.58754Z",
     "shell.execute_reply.started": "2026-01-23T22:25:56.981888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "print(len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:28:10.408696Z",
     "iopub.status.busy": "2026-01-23T22:28:10.408068Z",
     "iopub.status.idle": "2026-01-23T22:28:10.413937Z",
     "shell.execute_reply": "2026-01-23T22:28:10.413294Z",
     "shell.execute_reply.started": "2026-01-23T22:28:10.40867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "def build_densenet_model_fine(num_classes, activation):\n",
    "    # Charger DenseNet121 pré-entraîné\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # nous avons choisi d’entraîner 38 couches, \n",
    "    # c’est-à-dire que nous allons geler\n",
    "    # les 200 premières couches et dégeler les autres :\n",
    "    for layer in base_model.layers[:300]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[300:]:\n",
    "        layer.trainable = True \n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Dense(num_classes, activation=activation)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:28:15.875494Z",
     "iopub.status.busy": "2026-01-23T22:28:15.875228Z",
     "iopub.status.idle": "2026-01-23T22:28:17.520421Z",
     "shell.execute_reply": "2026-01-23T22:28:17.51982Z",
     "shell.execute_reply.started": "2026-01-23T22:28:15.875472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modèle 3 : Multi-classe (Glioma, Meningioma, Pituitary) avec Fine Tuning\n",
    "model_multi_dense_fine = build_densenet_model_fine(3, 'softmax')\n",
    "model_multi_dense_fine.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5), \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:28:23.620313Z",
     "iopub.status.busy": "2026-01-23T22:28:23.619651Z",
     "iopub.status.idle": "2026-01-23T22:28:23.625758Z",
     "shell.execute_reply": "2026-01-23T22:28:23.625016Z",
     "shell.execute_reply.started": "2026-01-23T22:28:23.620275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # Arrête l'entraînement si la perte de validation ne baisse plus pendant 3 époques\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss'),\n",
    "    # Réduit le LR si le modèle stagne\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:28:28.960388Z",
     "iopub.status.busy": "2026-01-23T22:28:28.95964Z",
     "iopub.status.idle": "2026-01-23T22:34:00.634772Z",
     "shell.execute_reply": "2026-01-23T22:34:00.634176Z",
     "shell.execute_reply.started": "2026-01-23T22:28:28.96036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lancement du Fine-tuning\n",
    "history_dense_fine = model_multi_dense_fine.fit(\n",
    "    train_gen_multi,\n",
    "    validation_data=val_gen_multi,\n",
    "    epochs=10, \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:35:11.697134Z",
     "iopub.status.busy": "2026-01-23T22:35:11.696352Z",
     "iopub.status.idle": "2026-01-23T22:35:12.017444Z",
     "shell.execute_reply": "2026-01-23T22:35:12.016717Z",
     "shell.execute_reply.started": "2026-01-23T22:35:11.697084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  courbes de perte (Loss) et d'Accuracy\n",
    "plot_training_history(history_dense_fine, title=\"Évolution de l'entraînement Multiclasse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T22:35:21.818156Z",
     "iopub.status.busy": "2026-01-23T22:35:21.817838Z",
     "iopub.status.idle": "2026-01-23T22:35:45.340449Z",
     "shell.execute_reply": "2026-01-23T22:35:45.339802Z",
     "shell.execute_reply.started": "2026-01-23T22:35:21.818132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation et matrice de confusion\n",
    "# Affichage pour le multiclasse\n",
    "evaluate_and_plot(model_multi_dense_fine, val_gen_multi, ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor'], \"Classification Multiclasse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T21:42:13.761467Z",
     "iopub.status.busy": "2026-01-22T21:42:13.76071Z",
     "iopub.status.idle": "2026-01-22T21:42:14.840686Z",
     "shell.execute_reply": "2026-01-22T21:42:14.839891Z",
     "shell.execute_reply.started": "2026-01-22T21:42:13.76144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_multi_dense_fine.save('model_multi_dense.h5') # Sauvegarde du modèle multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:07:37.6097Z",
     "iopub.status.busy": "2026-01-22T23:07:37.609407Z",
     "iopub.status.idle": "2026-01-22T23:07:37.615587Z",
     "shell.execute_reply": "2026-01-22T23:07:37.61491Z",
     "shell.execute_reply.started": "2026-01-22T23:07:37.609672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pipeline de décision finale\n",
    "\n",
    "def diagnostic_pipeline(image_path, model_bin, model_multi):\n",
    "    # 1. Charger et préparer l'image\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # 2. Étape 1 : Détection de tumeur (Binaire)\n",
    "    is_tumor_prob = model_bin.predict(img_array)[0][0]\n",
    "    \n",
    "    if is_tumor_prob < 0.5:\n",
    "        return \"Résultat : Absence de tumeur détectée.\"\n",
    "    else:\n",
    "        # 3. Étape 2 : Si tumeur, classifier le type (Multi-classe)\n",
    "        type_preds = model_multi.predict(img_array)\n",
    "        classes_multi = ['Glioma', 'Meningioma', 'Pituitary']\n",
    "        detected_type = classes_multi[np.argmax(type_preds)]\n",
    "        return f\"Résultat : Tumeur détectée. Type suspecté : {detected_type} (Confiance : {np.max(type_preds)*100:.2f}%)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T23:08:26.037324Z",
     "iopub.status.busy": "2026-01-22T23:08:26.037041Z",
     "iopub.status.idle": "2026-01-22T23:08:26.202731Z",
     "shell.execute_reply": "2026-01-22T23:08:26.20209Z",
     "shell.execute_reply.started": "2026-01-22T23:08:26.0373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_img_path = '/kaggle/input/brain-tumor-balanced/multiclass_classification/test/meningioma/image(109).jpg'\n",
    "\n",
    "diagnostic_pipeline(test_img_path, model_bin_dense, model_multi_dense_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Déploiement :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# 1. Chargement des modèles (une seule fois au démarrage)\n",
    "try:\n",
    "    binary_model = load_model('/kaggle/input/model-for-deployement/other/default/1/model_bin_eff.h5')\n",
    "    multi_model = load_model('/kaggle/input/model-for-deployement/other/default/1/model_multi_fine_partiel.h5')\n",
    "    print(\"Modèles chargés avec succès !\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de chargement : {e}\")\n",
    "\n",
    "def predict_tumor(input_img):\n",
    "    if input_img is None:\n",
    "        return \"Veuillez télécharger une image.\"\n",
    "\n",
    "    # 2. Préparation de l'image (Gradio fournit un array numpy)\n",
    "    img = tf.image.resize(input_img, (224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # 3. Prétraitement spécifique EfficientNet\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # 4. Étape 1 : Détection Binaire\n",
    "    is_tumor_prob = binary_model.predict(img_array)[0][0]\n",
    "    \n",
    "    # Seuil à 0.5 (ajustable si besoin)\n",
    "    if is_tumor_prob < 0.5:\n",
    "        return \" Résultat : Absence de tumeur détectée.\"\n",
    "    \n",
    "    # 5. Étape 2 : Classification si tumeur détectée\n",
    "    type_preds = multi_model.predict(img_array)[0]\n",
    "    classes_multi = ['Glioma', 'Meningioma', 'Pituitary']\n",
    "    \n",
    "    # Création d'un dictionnaire pour afficher les probabilités par classe dans Gradio\n",
    "    results = {classes_multi[i]: float(type_preds[i]) for i in range(3)}\n",
    "    \n",
    "    detected_type = classes_multi[np.argmax(type_preds)]\n",
    "    confiance = np.max(type_preds) * 100\n",
    "    \n",
    "    return f\" Tumeur détectée : {detected_type} ({confiance:.2f}%)\"\n",
    "\n",
    "# 6. Création de l'interface Gradio\n",
    "interface = gr.Interface(\n",
    "    fn=predict_tumor,\n",
    "    inputs=gr.Image(label=\"Uploader l'IRM du cerveau\"),\n",
    "    outputs=gr.Textbox(label=\"Diagnostic\"),\n",
    "    title=\"Système de Diagnostic de Tumeurs Cérébrales\",\n",
    "    description=\"Ce système utilise EfficientNet pour détecter la présence d'une tumeur, puis classer son type (Gliome, Méningiome ou Pituitaire).\",\n",
    "    examples=['/kaggle/input/brain-tumor-balanced/multiclass_classification/test/pituitary/image(10).jpg'] # Optionnel\n",
    ")\n",
    "\n",
    "# 7. Lancement\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 672377,
     "sourceId": 12745533,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9302022,
     "sourceId": 14562896,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 567937,
     "modelInstanceId": 555375,
     "sourceId": 729238,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
